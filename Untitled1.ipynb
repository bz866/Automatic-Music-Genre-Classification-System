{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import pickle \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import hamming_loss\n",
    "import time\n",
    "\n",
    "\n",
    "n = 20000\n",
    "\n",
    "num_tags = 1000\n",
    "\n",
    "#load all lyric data into pandas dataframe\n",
    "df = pd.read_csv('lyric_data.csv', index_col=0)\n",
    "\n",
    "# Sometimes the API returns an error message rather than actual lyrics. This removes it\n",
    "bad_song = df['lyrics'].value_counts().index[0]\n",
    "df[df['lyrics'] == bad_song] = ''\n",
    "\n",
    "# only take the ones that we have data for\n",
    "df.fillna('', inplace=True)\n",
    "df = df[df['lyrics'] != '']\n",
    "\n",
    "# List of list of tags for each example\n",
    "tags = [clean_tags(raw) for raw in list(df['tags'])]\n",
    "\n",
    "# list of tuples of (tag, frequency) in desending order\n",
    "tf = tag_freq(tags)\n",
    "\n",
    "# Choose which tags to restrict model too\n",
    "important_tags = [x[0] for x in tf[0:num_tags]]\n",
    "important_tags = dict(zip(important_tags, range(len(important_tags))))\n",
    "\n",
    "# maps each of the tags int 'tags' to an int index\n",
    "indices = tag2index(tags, important_tags)\n",
    "\n",
    "# Convert indices to binary vectors of tags\n",
    "y = np.zeros((len(indices), num_tags))\n",
    "for i, tags in enumerate(indices):\n",
    "    for tag in tags:\n",
    "        y[i, tag] = 1\n",
    "\n",
    "# Build vocabulary and tokenizer\n",
    "vect = CountVectorizer(max_features=n, stop_words='english')\n",
    "X = vect.fit_transform(df['lyrics'])\n",
    "X = X.toarray()\n",
    "vocab = vect.vocabulary_\n",
    "tok = vect.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/Hadoop/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-176142fc8333>\", line 1, in <module>\n",
      "    X = X.toarray()\n",
      "AttributeError: 'numpy.ndarray' object has no attribute 'toarray'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Hadoop/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'AttributeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Hadoop/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/Hadoop/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/Hadoop/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/Hadoop/anaconda3/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/Hadoop/anaconda3/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/Hadoop/anaconda3/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/Hadoop/anaconda3/lib/python3.5/inspect.py\", line 715, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/Users/Hadoop/anaconda3/lib/python3.5/inspect.py\", line 685, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/Hadoop/anaconda3/lib/python3.5/posixpath.py\", line 363, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/Users/Hadoop/anaconda3/lib/python3.5/posixpath.py\", line 349, in normpath\n",
      "    path = sep.join(comps)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "X = X.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "tag_features = np.zeros((num_tags,n))\n",
    "\n",
    "for i in range(num_tags):\n",
    "\n",
    "    mask = y[:,i] == 1\n",
    "    \n",
    "    tag_features[i] = (X[mask].mean(axis=0) > .01)\n",
    "    \n",
    "    if i%100==0:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My pop music 200\n",
      "['ah', 'ain', 'alright', 'away', 'babe', 'baby', 'bad', 'believe', 'best', 'better', 'big', 'blue', 'boy', 'bring', 'care', 'cause', 'change', 'cold', 'come', 'comes', 'coming', 'day', 'days', 'did', 'didn', 'don', 'doo', 'door', 'dream', 'dreams', 'end', 'everybody', 'eyes', 'face', 'fall', 'far', 'feel', 'feeling', 'feet', 'fine', 'free', 'girl', 'god', 'goes', 'going', 'gone', 'gonna', 'good', 'got', 'gotta', 'hand', 'hands', 'hard', 'head', 'hear', 'heart', 'hey', 'high', 'hold', 'home', 'hope', 'inside', 'just', 'knew', 'know', 'knows', 'la', 'leave', 'left', 'let', 'life', 'light', 'like', 'line', 'little', 'live', 'll', 'lonely', 'long', 'look', 'looking', 'lord', 'lost', 'love', 'make', 'makes', 'man', 'matter', 'maybe', 'mean', 'mind', 'money', 'morning', 'na', 'need', 'new', 'night', 'oh', 'old', 'ooh', 'people', 'place', 'play', 'pretty', 'rain', 'really', 'remember', 'right', 'road', 'rock', 'roll', 'round', 'run', 'said', 'say', 'says', 'seen', 'sing', 'sky', 'sleep', 'song', 'soul', 'stand', 'start', 'stay', 'stop', 'street', 'sun', 'sweet', 'talk', 'tell', 'thing', 'things', 'think', 'thought', 'time', 'times', 'today', 'told', 'tonight', 'took', 'town', 'train', 'true', 'try', 'trying', 'turn', 'used', 've', 'wait', 'waiting', 'walk', 'walking', 'wanna', 'want', 'way', 'whoa', 'wish', 'woman', 'won', 'words', 'work', 'world', 'wrong', 'yeah', 'yes']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i=200\n",
    "\n",
    "mask = y[:,i] == 1    \n",
    "tag_features[i] = (X[mask].mean(axis=0) > .01)\n",
    "for v,k in important_tags.items():\n",
    "    if k ==i:\n",
    "        print(v,k)\n",
    "print(list(vect.inverse_transform(X[mask].mean(axis=0) > .1 )[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08935909025836736\n",
      "0.0238095238095 0.06325256782583892\n",
      "0.06559160753153265\n",
      "0.0315955766193 0.08499445538036525\n",
      "0.07150043869391084\n",
      "0.0157728706625 0.04971848330460489\n",
      "0.0681358005013317\n",
      "0.0266666666667 0.07414181013591588\n",
      "0.06555419113021344\n",
      "0.0320512820513 0.08411665423773229\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "W = nn.Linear(20000, 1, bias=True)\n",
    "    \n",
    "opt = optim.SGD(W.parameters(), lr=0.001)\n",
    "\n",
    "bce = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "def train(X_song, X_tag ,y):\n",
    "    \n",
    "    n_batches = 20\n",
    "    epochs = 10\n",
    "    avg_loss = 0\n",
    "\n",
    "    for e in range(epochs):\n",
    "                \n",
    "        for i in range(n_batches):\n",
    "        \n",
    "            song_idx = np.random.permutation(X_song.shape[0])[0:64]\n",
    "            tag_idx = np.random.permutation(X_tag.shape[0])[0:64]\n",
    "            \n",
    "            song_batch = Variable(torch.from_numpy(X_song[song_idx].astype(np.float32)))\n",
    "            tag_batch = Variable(torch.from_numpy(X_tag[tag_idx].astype(np.float32)))\n",
    "            target = Variable( torch.from_numpy( y[song_idx,tag_idx]).float() )\n",
    "            \n",
    "            delta= (song_batch - tag_batch).abs()\n",
    "\n",
    "            y_hat = F.sigmoid( W(delta))\n",
    "            \n",
    "            opt.zero_grad()\n",
    "\n",
    "            loss = bce(y_hat, target)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            avg_loss += loss.data[0]\n",
    "            \n",
    "            #print(loss.data[0])\n",
    "    \n",
    "    print(avg_loss / n_batches / epochs)\n",
    "        \n",
    "        \n",
    "def test(X_song, X_tag ,y):\n",
    "    \n",
    "    n_batches = 20\n",
    "    avg_loss =0\n",
    "    y_hat_all = np.zeros(n_batches*64)\n",
    "    y_all = np.zeros(n_batches*64)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        \n",
    "        song_idx = np.random.permutation(X_song.shape[0])[0:64]\n",
    "        tag_idx = np.random.permutation(X_tag.shape[0])[0:64]\n",
    "\n",
    "        song_batch = Variable(torch.from_numpy(X_song[song_idx].astype(np.float32)))\n",
    "        tag_batch = Variable(torch.from_numpy(X_tag[tag_idx].astype(np.float32)))\n",
    "        target = Variable( torch.from_numpy( y[song_idx,tag_idx]).float() )\n",
    "\n",
    "        delta= (song_batch - tag_batch).abs()\n",
    "\n",
    "        y_hat = F.sigmoid( W(delta))\n",
    "        \n",
    "        y_hat_all[i*64:(i+1)*64] = y_hat.data.numpy().flatten()\n",
    "        y_all[i*64:(i+1)*64] = y[song_idx,tag_idx]\n",
    "        \n",
    "        loss = bce(y_hat, target)\n",
    "\n",
    "        avg_loss += loss.data[0]\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_all.flatten(), y_hat_all.flatten())\n",
    "    \n",
    "    f_score = 2* precision * recall / (precision + recall)\n",
    "    i_max = np.nanargmax(f_score)\n",
    "    f_max = f_score[i_max]\n",
    "    max_thresh = thresholds[i_max]\n",
    "        \n",
    "    print( f_max , avg_loss / n_batches)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    train(X , tag_features , y)\n",
    "    test(X , tag_features , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "W = nn.Linear(1, 1, bias=True)\n",
    "    \n",
    "opt = optim.SGD(W.parameters(), lr=0.001)\n",
    "\n",
    "bce = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "def train(X_song, X_tag ,y):\n",
    "    \n",
    "    n_batches = 20\n",
    "    epochs = 10\n",
    "    avg_loss = 0\n",
    "\n",
    "    for e in range(epochs):\n",
    "                \n",
    "        for i in range(n_batches):\n",
    "        \n",
    "            song_idx = np.random.permutation(X_song.shape[0])[0:64]\n",
    "            tag_idx = np.random.permutation(X_tag.shape[0])[0:64]\n",
    "            \n",
    "            song_batch = Variable(torch.from_numpy(X_song[song_idx].astype(np.float32)))\n",
    "            tag_batch = Variable(torch.from_numpy(X_tag[tag_idx].astype(np.float32)))\n",
    "            target = Variable( torch.from_numpy( y[song_idx,tag_idx]).float() )\n",
    "            \n",
    "            delta= (song_batch - tag_batch).abs().mean()\n",
    "\n",
    "            y_hat = F.sigmoid( W(delta))\n",
    "            \n",
    "            opt.zero_grad()\n",
    "\n",
    "            loss = bce(y_hat, target)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            avg_loss += loss.data[0]\n",
    "                \n",
    "    print(avg_loss / n_batches / epochs)\n",
    "        \n",
    "        \n",
    "def test(X_song, X_tag ,y):\n",
    "    \n",
    "    n_batches = 20\n",
    "    avg_loss =0\n",
    "    y_hat_all = np.zeros(n_batches*64)\n",
    "    y_all = np.zeros(n_batches*64)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        \n",
    "        song_idx = np.random.permutation(X_song.shape[0])[0:64]\n",
    "        tag_idx = np.random.permutation(X_tag.shape[0])[0:64]\n",
    "\n",
    "        song_batch = Variable(torch.from_numpy(X_song[song_idx].astype(np.float32)))\n",
    "        tag_batch = Variable(torch.from_numpy(X_tag[tag_idx].astype(np.float32)))\n",
    "        target = Variable( torch.from_numpy( y[song_idx,tag_idx]).float() )\n",
    "\n",
    "        delta= (song_batch - tag_batch).abs().mean()\n",
    "\n",
    "        y_hat = F.sigmoid( W(delta))\n",
    "        \n",
    "        y_hat_all[i*64:(i+1)*64] = y_hat.data.numpy().flatten()\n",
    "        y_all[i*64:(i+1)*64] = y[song_idx,tag_idx]\n",
    "        \n",
    "        loss = bce(y_hat, target)\n",
    "\n",
    "        avg_loss += loss.data[0]\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_all.flatten(), y_hat_all.flatten())\n",
    "    \n",
    "    f_score = 2* precision * recall / (precision + recall)\n",
    "    i_max = np.nanargmax(f_score)\n",
    "    f_max = f_score[i_max]\n",
    "    max_thresh = thresholds[i_max]\n",
    "        \n",
    "    print( f_max , avg_loss / n_batches)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    train(X , tag_features , y)\n",
    "    test(X , tag_features , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ad44b749f0a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_hat_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_song\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tag\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_batches' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
